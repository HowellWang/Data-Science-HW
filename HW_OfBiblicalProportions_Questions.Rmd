---
title: "A Homework of Biblical Proportions"
author: "Yuhao Wang & Meiyuan Li"
output: html_document
---

In this HW, we will analyze the text of the bible. The ascii version resides in the file "ascii_bible.txt" on Camino. Use an editor to familiarize yourself with the structure of the file. Then perform the following operations, listed below as questions for you to answer. 

## Q1: Read in the file using any R function you like and store each verse in a text array. After which print the top 20 verses. (Remove the top two lines which contain the title.)
```{r}
library(stringr)
text <- readLines("/Users/yuhaowang/Downloads/ascii_bible.txt")
text <- str_replace(text,"^\\s+","")
verses_len <- grep("[0-9][0-9][0-9]:[0-9][0-9][0-9]",text)
helper <- NULL
for (i in seq(1:(length(verses_len)-1))){
  temp <- paste(text[verses_len[i]:(verses_len[i+1]-1)],collapse = " ")
  helper <- c(helper,temp)
}
verses <- c(helper,paste(text[verses_len[length(verses_len)]:length(text)],collapse = " "))
verses[1:20]
```

## Q2: How many verses are there in total? 
```{r}
length(verses)
```

## Q3: Each verse has the number "CCC:VVV" where CCC is the chapter number and VVV is the verse number. How many chapters are there? 
```{r}
chapter <- grep("[0-9][0-9][0-9]:001", verses)
length(chapter)
```

## Q4: Extract an array for the verse numbers, and also one for the verse text.
```{r}
verses_no <- c(substr(verses,5,7))
verses_text <-  str_split_fixed(verses, "[0-9][0-9][0-9]:[0-9][0-9][0-9] ",2)
verses_text <- verses_text[,2]
head(verses_no)
head(verses_text)
```

## Q5: Lower case all text.
```{r}
verses_text <- str_to_lower(verses_text)
head(verses_text)
```

## Q6: Convert the text of all verses into a Corpus using the **tm** package. 
```{r}
library(NLP)
library(tm)
verses_text <- Corpus(VectorSource(verses_text))
verses_text
```

## Q7: Remove all punctuation. Use a corpus function for this. How many unique words are there in the bible? 
```{r}
verses_text <- tm_map(verses_text, removePunctuation)
verses_unique <- DocumentTermMatrix(verses_text)
verses_unique
#12651 unique words
```

## Q8: Remove all stopwords. Now how many unique terms are there? 
```{r}
verses_stop <- verses_text
verses_stop <- tm_map(verses_stop, removeWords, stopwords("english"))
verses_stop_uniq <- DocumentTermMatrix(verses_stop)
verses_stop_uniq
#12555 unique terms
```

## Q9: Now stem the text, to remove multiplicity of similar words of the same root. 
```{r}
verses_stem <- tm_map(verses_stop, stemDocument)
verses_stem
```

## Q10: How many distinct words are there in the bible, after stemming?
```{r}
verses_stem_unique <- DocumentTermMatrix(verses_stem)
verses_stem_unique
#9125 distinct words
```

## Q11: Convert the TDM into a matrix and find the 50 most common words in the bible. 
```{r}
verses_rmv_spr <- removeSparseTerms(verses_stem_unique, 0.99)
verses_m <- as.matrix(verses_rmv_spr)
wordcount <- sort(colSums(verses_m), decreasing = TRUE)
head(wordcount, 50)
```

## Q12: Make a wordcloud of the top 100 words in the bible. 
```{r}
library(wordcloud)
wordcloud(names(head(wordcount, 100)), head(wordcount, 100))
```

## Q13: Mood score the original text of the bible (before stemming)
```{r}
HIDict <- readLines("/Users/yuhaowang/Downloads/inqdict.txt")
dict_pos <- HIDict[grep("Pos",HIDict)]
poswords <- NULL
for (s in dict_pos) {
    s <- strsplit(s,"#")[[1]][1]
    poswords <- c(poswords,strsplit(s," ")[[1]][1])
}
dict_neg <- HIDict[grep("Neg",HIDict)]
negwords <- NULL
for (s in dict_neg) {
    s <- strsplit(s,"#")[[1]][1]
    negwords <- c(negwords,strsplit(s," ")[[1]][1])
}
poswords <- tolower(poswords)
negwords <- tolower(negwords)
poswords <- unique(poswords)
negwords <- unique(negwords)


verses_mood <-  str_split_fixed(verses, "[0-9][0-9][0-9]:[0-9][0-9][0-9] ",2)
verses_mood <- verses_mood[,2] 
verses_mood <- Corpus(VectorSource(verses_mood))
verses_mood <- tm_map(verses_mood,removePunctuation)
verses_mood <- data.frame(text = sapply(verses_mood, as.character), stringsAsFactors = FALSE) 
verses_mood <- str_replace(verses_mood$text,"^\\s+","")  
verses_mood <- trimws(verses_mood,which = "right") 
verses_mood <- str_to_lower(verses_mood) 
verses_mood1 <- unlist(strsplit(verses_mood," ")) 
posmatch <- match(verses_mood1,poswords)
posmatch_no <- length(posmatch[which(posmatch>0)])
negmatch <- match(verses_mood1,negwords)
negmatch_no <- length(negmatch[which(negmatch>0)])
print(c(posmatch_no,negmatch_no))

```

## Q14: Summarize the bible into less than 500 verses. (Or some fraction of the total number of verses, it's your choice.) Be super careful here as this may take a long time unless you are clever about it, or find some elegant way to speed things up!
```{r}
text_summary <- function(text, n) {
  m <- length(text)  # No of sentences in input
  jaccard <- matrix(0,m,m)  #Store match index
  for (i in 1:m) {
    for (j in i:m) {
      a <- text[i]; aa <- unlist(strsplit(a," "))
      b <- text[j]; bb <- unlist(strsplit(b," "))
      jaccard[i,j] <- length(intersect(aa,bb))/
                          length(union(aa,bb))
      jaccard[j,i] <- jaccard[i,j]
    }
  }
  similarity_score <- rowSums(jaccard)
  res <- sort(similarity_score, index.return=TRUE,
          decreasing=TRUE)
  idx <- res$ix[1:n]
  summary <- text[idx]
}

a <- c(2,2)
b <- c(2,2)
temp <- data.frame(a,b)
column_names <- c("Verse")
temp = `colnames<-`(temp,column_names)
count <- 1
for(verse in verses_mood){
  ver <- unlist(strsplit(verse," "))
  posmatch <- match(ver,poswords)
  numposmatch <- length(posmatch[which(posmatch>0)])
  negmatch <- match(ver,negwords)
  numnegmatch = length(negmatch[which(negmatch>0)])
  if(numposmatch > 5 | numnegmatch > 5){
    temp[count,1] <- verse
    count <- count + 1
  }
}

summary <- text_summary(temp$Verse, 500)
print(summary)
```

## Q15: Find the main 3 topics in the bible, and the top 25 words in each topic. Can you find an interpretation of each topic?
```{r}
library(topicmodels)
verses_m <- verses_m[apply(verses_m[,-1], 1, function(x) !all(x==0)),]
lda <- LDA(verses_m, k=3) 
(term <- terms(lda, 25)) 
```

